{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill missing value of aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "info_df = pd.read_csv(\"./data/lose_hour_record.csv\")\n",
    "aq_df = pd.read_csv(\"./data/air_quality_concated.csv\")\n",
    "\n",
    "# info_df[(info_df[\"pollutant\"] == \"PM2.5\") & (info_df[\"counts\"] >= 3000)].index.tolist()\n",
    "# info_df[info_df[\"counts\"] == 3][1000:1002]\n",
    "# info_df.iloc[0].index\n",
    "fill_threshold = 6\n",
    "info_df.counts.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_df:['stationId', 'pollutant', 'start_time', 'counts']\n",
    "# aq_df:stationId time PM2.5  PM10 NO2 CO O3 SO2 \n",
    "\n",
    "new_info_df = info_df[info_df[\"counts\"] <= fill_threshold]\n",
    "print(new_info_df.shape[0])\n",
    "pollutants = [\"PM2.5\", \"PM10\", \"NO2\", \"CO\", \"O3\" \"SO2\"]\n",
    "\n",
    "d_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "# first filter counts <= threshold \n",
    "\n",
    "def shift_time(date_str, shift):\n",
    "    new_date = datetime.strptime(date_str, d_format) + pd.Timedelta(\"{} hour\".format(str(shift)))\n",
    "    new_str = datetime.strftime(new_date, d_format)\n",
    "    return new_str\n",
    "\n",
    "def fill_na_values(i_df):\n",
    "    counts = i_df[\"counts\"]\n",
    "    \n",
    "    start_time = i_df[\"start_time\"]\n",
    "    # check whether continuous na on the bottom\n",
    "\n",
    "    last_not_na_time = shift_time(start_time,-1)\n",
    "    next_not_na_time = shift_time(start_time,counts)\n",
    "\n",
    "    pollutant = i_df[\"pollutant\"]\n",
    "\n",
    "    last_df = aq_df[(aq_df[\"stationId\"] == i_df[\"stationId\"]) & \\\n",
    "                       (aq_df[\"time\"] == last_not_na_time)]\n",
    "\n",
    "    start_index = last_df.index.tolist()[0] + 1\n",
    "\n",
    "    next_df = aq_df[(aq_df[\"stationId\"] == i_df[\"stationId\"]) & \\\n",
    "                       (aq_df[\"time\"] == next_not_na_time)]\n",
    "\n",
    "    last_value = last_df[pollutant].iloc[0]\n",
    "    next_value = next_df[pollutant].iloc[0]\n",
    "\n",
    "    interval = (next_value-last_value) / (counts+1)\n",
    "\n",
    "    for i in range(counts):\n",
    "#             aq_df.iloc[i+start_index][pollutant] = (last_value + (i+1)*interval)\n",
    "        aq_df.set_value((i+start_index),pollutant,(last_value + (i+1)*interval))\n",
    "\n",
    "    # what if next_not_na_time out of bound?\n",
    "        \n",
    "        \n",
    "new_info_df = new_info_df.iloc[20100:20200]\n",
    "new_info_df.apply(fill_na_values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_df = aq_df.interpolate(limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill grid weather's na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "data_path = \"../MSBD5002PROJECT_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load air quality file and grid weather file\n",
    "aq_df = pd.read_csv(\"../MSBD5002PROJECT_data/air_quality_concated.csv\")\n",
    "grid_df = pd.read_csv(\"../MSBD5002PROJECT_data/grid_weather_1701_1804_unfill.csv\")\n",
    "# grid_4_df = pd.read_csv(\"../MSBD5002PROJECT_data/gridWeather_201804.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_range(str_start='2018-04-01 00:00:00',str_end='2018-04-30 23:00:00'):\n",
    "    timeFrom = datetime.strptime(str_start, \"%Y-%m-%d %H:%M:%S\")\n",
    "    timeTo = datetime.strptime(str_end,\"%Y-%m-%d %H:%M:%S\")\n",
    "    Hours_Delta = pd.date_range(timeFrom, timeTo, freq='H').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return Hours_Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7498182 entries, 0 to 7498181\n",
      "Data columns (total 7 columns):\n",
      "humidity          float64\n",
      "pressure          float64\n",
      "station_id        object\n",
      "temperature       float64\n",
      "time              object\n",
      "wind_direction    float64\n",
      "wind_speed        float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 400.4+ MB\n"
     ]
    }
   ],
   "source": [
    "aq_df.time.unique()\n",
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_grid_df = grid_df[grid_df[\"time\"] >= \"2018-04-01 00:00:00\"]\n",
    "station_rows = {}\n",
    "\n",
    "for grid in grid_df.station_id.unique():\n",
    "    each_station = apr_grid_df[apr_grid_df[\"station_id\"] == grid].shape[0]\n",
    "    station_rows[grid] = each_station\n",
    "\n",
    "# missing_time_grid_stations = [i for i in station_rows.keys() if station_rows[i] != 712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Times_missed = {}\n",
    "grid_items = ['humidity', 'pressure', 'temperature', 'wind_direction', 'wind_speed']\n",
    "Stations = apr_grid_df.station_id.unique()\n",
    "for station in Stations:\n",
    "    Times_missed[station] = {}\n",
    "    # Find time not in rows.\n",
    "    tmp = apr_grid_df[apr_grid_df['station_id']==station].time.unique()\n",
    "    tmp = list(set(time_range()) - set(tmp))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(tmp, columns=['time'])\n",
    "    tmp_df['station_id'] = station\n",
    "    for item in grid_items:\n",
    "        tmp_df[item] = np.nan\n",
    "    tmp_df = tmp_df[apr_grid_df.columns]\n",
    "    apr_grid_df = pd.concat([apr_grid_df, tmp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_grid_df = apr_grid_df.sort_values(by=['station_id','time'])\n",
    "apr_grid_df = apr_grid_df.reset_index(drop=True)\n",
    "apr_grid_df.to_csv(data_path+'grid_04_timestamp_filled.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(data_path+\"grid_04_timestamp_filled.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(data_path+'grid_04_timestamp_filled.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_rows = {}\n",
    "for grid in a.station_id.unique():\n",
    "    each_station = a[a[\"station_id\"] == grid].shape[0]\n",
    "    station_rows[grid] = each_station\n",
    "\n",
    "\n",
    "dup_time_grid_stations = [i for i in station_rows.keys() if station_rows[i] > 720]\n",
    "dup_time_grid_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.interpolate(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humidity          False\n",
       "pressure          False\n",
       "station_id        False\n",
       "temperature       False\n",
       "time              False\n",
       "wind_direction    False\n",
       "wind_speed        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(data_path+'grid_04_all_filled.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
