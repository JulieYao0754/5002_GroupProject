{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_path = './data/'\n",
    "model_path = './model/'\n",
    "source_data_path = './data/MSBD5002PROJECT_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Air Quality Data (on hourly basis)  \n",
    "The Air Quality Data file contains the concentration of PM2.5 (ug/m3), PM10 (ug/m3), NO2 (ug/m3),\n",
    "CO (mg/m3), O3 (ug/m3) and SO2 (ug/m3) from Beijing. Your group only need to predict the\n",
    "concentration of PM2.5, PM10 and O3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). airQuality_201701-201801.csv &emsp; January 2017 to January 2018  \n",
    "2). airQuality_201802-201803.csv &emsp; From February 2018 to March 2018  \n",
    "3). airQuality_201804.csv &emsp; &emsp; &emsp; &emsp; April 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data\n",
    "AQ_Jan = pd.read_csv(source_data_path+'airQuality_201701-201801.csv')\n",
    "AQ_Mar = pd.read_csv(source_data_path+'airQuality_201802-201803.csv')\n",
    "AQ_Apr = pd.read_csv(source_data_path+'airQuality_201804.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we combined the three datasets, check all columns' names are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del AQ_Apr.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AQ_Jan.rename(columns={'utc_time':'time'}, inplace=True)\n",
    "AQ_Mar.rename(columns={'utc_time':'time'}, inplace=True)\n",
    "AQ_Apr.rename(columns={'station_id':'stationId',\\\n",
    "                       'PM25_Concentration':'PM2.5','PM10_Concentration':'PM10',\\\n",
    "                       'NO2_Concentration':'NO2', 'CO_Concentration':'CO',\\\n",
    "                       'O3_Concentration':'O3','SO2_Concentration':'SO2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stationId', 'time', 'PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2'], dtype='object')\n",
      "Index(['stationId', 'time', 'PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2'], dtype='object')\n",
      "Index(['stationId', 'time', 'PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(AQ_Jan.columns)\n",
    "print(AQ_Mar.columns)\n",
    "print(AQ_Apr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 14:00:00\n",
      "2018-01-31 15:00:00\n",
      "2018-01-31 16:00:00\n",
      "2018-03-31 15:00:00\n",
      "2018-04-01 02:00:00\n",
      "2018-04-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "print(AQ_Jan.time.min())\n",
    "print(AQ_Jan.time.max())\n",
    "print(AQ_Mar.time.min())\n",
    "print(AQ_Mar.time.max())\n",
    "print(AQ_Apr.time.min())\n",
    "print(AQ_Apr.time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# All stations in AQ_Jan and AQ_Mar and AQ_Apr are the same. \n",
    "print(set(AQ_Jan.stationId.unique()) ^ set(AQ_Mar.stationId.unique()))\n",
    "print(set(AQ_Jan.stationId.unique()) ^ set(AQ_Apr.stationId.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 PreProcess AQ_Jan(Drop Duplicated rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed air quality data firstly. There are 35 air quality stations who recorded pollutant concentrations from 2pm, Jan 1st, 2017 to 3pm, Jan 31th, 2018, with missed data. So we tried to find out missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311010 entries, 0 to 311009\n",
      "Data columns (total 8 columns):\n",
      "stationId    311010 non-null object\n",
      "time         311010 non-null object\n",
      "PM2.5        290621 non-null float64\n",
      "PM10         227747 non-null float64\n",
      "NO2          292359 non-null float64\n",
      "CO           268197 non-null float64\n",
      "O3           290589 non-null float64\n",
      "SO2          292462 non-null float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "AQ_Jan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Stations: 35\n",
      "Count of TimeStamp(Hours): 8701\n"
     ]
    }
   ],
   "source": [
    "print('Count of Stations: {0}'.format(len(AQ_Jan.stationId.unique())))\n",
    "print('Count of TimeStamp(Hours): {0}'.format(len(AQ_Jan.time.unique())))\n",
    "# 35 x 8701 = 304535, But number of rows is 311010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "duplicated_column = pd.DataFrame(columns=AQ_Jan.columns.tolist())\n",
    "for i, value in enumerate(AQ_Jan.duplicated()):\n",
    "    if value:\n",
    "        duplicated_column.loc[counter] = AQ_Jan.loc[i]\n",
    "        counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 304535 entries, 0 to 311009\n",
      "Data columns (total 8 columns):\n",
      "stationId    304535 non-null object\n",
      "time         304535 non-null object\n",
      "PM2.5        284771 non-null float64\n",
      "PM10         222667 non-null float64\n",
      "NO2          286480 non-null float64\n",
      "CO           262301 non-null float64\n",
      "O3           284701 non-null float64\n",
      "SO2          286575 non-null float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop duplicated row in AQ_Jan\n",
    "AQ_Jan = AQ_Jan.drop_duplicates()\n",
    "AQ_Jan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Combine all data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.concat([AQ_Jan, AQ_Mar, AQ_Apr], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort \"air_quality\" by stationId and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = air_quality.sort_values(by=['stationId','time'])\n",
    "air_quality = air_quality.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns 'CO','NO2','SO2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = air_quality.drop(columns=['CO','NO2','SO2'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Find Outlier values(only consider PM2.5, PM10, O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pollutants = air_quality.columns[2:5].tolist()\n",
    "Stations = air_quality.stationId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat(df, attr):\n",
    "    max_ = df[[attr]].max()\n",
    "    min_ = df[[attr]].min()\n",
    "    median_ = df[[attr]].median()\n",
    "    mean_ = df[[attr]].mean()\n",
    "    return np.hstack((max_, min_, median_, mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistical information of PM2.5 is :\n",
      "\tMax: 1574.0\tMin: 2.0\tMedian: 40.0\tMean: 61.285504365847856\n",
      "The statistical information of PM10 is :\n",
      "\tMax: 3280.0\tMin: 5.0\tMedian: 73.0\tMean: 93.87728746397694\n",
      "The statistical information of O3 is :\n",
      "\tMax: 504.0\tMin: 1.0\tMedian: 48.0\tMean: 56.53468696164657\n"
     ]
    }
   ],
   "source": [
    "for pollutant in Pollutants:\n",
    "    pollutant_stat = get_stat(air_quality, pollutant)\n",
    "    print('The statistical information of {0} is :\\n\\tMax: {1}\\tMin: {2}\\tMedian: {3}\\tMean: {4}'\\\n",
    "          .format(pollutant, \\\n",
    "                  str(pollutant_stat[0]), str(pollutant_stat[1]), \n",
    "                  str(pollutant_stat[2]), str(pollutant_stat[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pyecharts into Notebook\n",
    "1. Make sure you have nodeJs on your laptop.\n",
    "2. npm install -g phantomjs-prebuilt\n",
    "3. pip install pyecharts-snapshot\n",
    "4. pip install pyecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import Scatter\n",
    "scatter = Scatter(\"Scatter Plot: Find outlier values\",\n",
    "                  width=1200,height=600)\n",
    "for pollutant in Pollutants:\n",
    "    scatter.add(pollutant,\n",
    "                air_quality[pollutant].dropna().index,\n",
    "                air_quality[pollutant].dropna().values.flatten(),\n",
    "                is_datazoom_show=True,\n",
    "                datazoom_orient='vertical',\n",
    "                datazoom_range=[80,100],\n",
    "                legend_top='30',\n",
    "                mark_line=\"average\",\n",
    "                legend_selectedmode='single',\n",
    "                is_toolbox_show=False\n",
    "               )\n",
    "scatter.render('./image/Outliers.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers of PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>time</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139411</th>\n",
       "      <td>huairou_aq</td>\n",
       "      <td>2018-03-29 14:00:00</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347640</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>2017-05-05 02:00:00</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347641</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>2017-05-05 03:00:00</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stationId                 time   PM2.5  PM10    O3\n",
       "139411  huairou_aq  2018-03-29 14:00:00  1574.0   NaN  60.0\n",
       "347640     yufa_aq  2017-05-05 02:00:00  1004.0   NaN  99.0\n",
       "347641     yufa_aq  2017-05-05 03:00:00  1004.0   NaN  86.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality[air_quality['PM2.5']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# air_quality.iloc[139411,2]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers of O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>time</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>badaling_aq</td>\n",
       "      <td>2017-07-12 08:00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>badaling_aq</td>\n",
       "      <td>2017-08-01 23:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33220</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-02-09 20:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33316</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-02-13 20:00:00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33412</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-02-17 20:00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33457</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-02-19 20:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33590</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>2017-02-25 20:00:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44639</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-03-09 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44719</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-03-17 00:00:00</td>\n",
       "      <td>113.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44771</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-03-19 04:00:00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-03-26 23:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44986</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-03-28 03:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45531</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-04-20 13:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45837</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>2017-05-05 11:00:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60804</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60805</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 15:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60806</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 16:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60807</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 17:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60808</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 18:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60809</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 19:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60810</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 20:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60811</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 21:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60812</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 22:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60813</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-17 23:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60814</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-18 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60815</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>2017-11-18 01:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64787</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>2017-01-06 07:00:00</td>\n",
       "      <td>245.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86597</th>\n",
       "      <td>fangshan_aq</td>\n",
       "      <td>2017-01-16 19:00:00</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253686</th>\n",
       "      <td>tiantan_aq</td>\n",
       "      <td>2017-09-30 23:00:00</td>\n",
       "      <td>168.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265502</th>\n",
       "      <td>tongzhou_aq</td>\n",
       "      <td>2017-11-13 07:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265503</th>\n",
       "      <td>tongzhou_aq</td>\n",
       "      <td>2017-11-13 08:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stationId                 time  PM2.5   PM10     O3\n",
       "14629     badaling_aq  2017-07-12 08:00:00  140.0  214.0  474.0\n",
       "15117     badaling_aq  2017-08-01 23:00:00   30.0    NaN  500.0\n",
       "33220       daxing_aq  2017-02-09 20:00:00    3.0   13.0  500.0\n",
       "33316       daxing_aq  2017-02-13 20:00:00  134.0  146.0  500.0\n",
       "33412       daxing_aq  2017-02-17 20:00:00  140.0  156.0  500.0\n",
       "33457       daxing_aq  2017-02-19 20:00:00    5.0   25.0  500.0\n",
       "33590       daxing_aq  2017-02-25 20:00:00   19.0   41.0  500.0\n",
       "44639     dingling_aq  2017-03-09 12:00:00    6.0   23.0  500.0\n",
       "44719     dingling_aq  2017-03-17 00:00:00  113.0  172.0  500.0\n",
       "44771     dingling_aq  2017-03-19 04:00:00  250.0    NaN  500.0\n",
       "44958     dingling_aq  2017-03-26 23:00:00   14.0   24.0  500.0\n",
       "44986     dingling_aq  2017-03-28 03:00:00   72.0  102.0  500.0\n",
       "45531     dingling_aq  2017-04-20 13:00:00    7.0   41.0  500.0\n",
       "45837     dingling_aq  2017-05-05 11:00:00   19.0  123.0  499.0\n",
       "60804   donggaocun_aq  2017-11-17 14:00:00    NaN    NaN  500.0\n",
       "60805   donggaocun_aq  2017-11-17 15:00:00    7.0   28.0  500.0\n",
       "60806   donggaocun_aq  2017-11-17 16:00:00   12.0   23.0  500.0\n",
       "60807   donggaocun_aq  2017-11-17 17:00:00    5.0   18.0  500.0\n",
       "60808   donggaocun_aq  2017-11-17 18:00:00    5.0   19.0  500.0\n",
       "60809   donggaocun_aq  2017-11-17 19:00:00   10.0   16.0  500.0\n",
       "60810   donggaocun_aq  2017-11-17 20:00:00    3.0   25.0  500.0\n",
       "60811   donggaocun_aq  2017-11-17 21:00:00   12.0   24.0  500.0\n",
       "60812   donggaocun_aq  2017-11-17 22:00:00    7.0   24.0  500.0\n",
       "60813   donggaocun_aq  2017-11-17 23:00:00    4.0   18.0  500.0\n",
       "60814   donggaocun_aq  2017-11-18 00:00:00    4.0   11.0  500.0\n",
       "60815   donggaocun_aq  2017-11-18 01:00:00    9.0   10.0  500.0\n",
       "64787       dongsi_aq  2017-01-06 07:00:00  245.0  256.0  500.0\n",
       "86597     fangshan_aq  2017-01-16 19:00:00  125.0    NaN  504.0\n",
       "253686     tiantan_aq  2017-09-30 23:00:00  168.0  181.0  500.0\n",
       "265502    tongzhou_aq  2017-11-13 07:00:00    5.0  124.0  495.0\n",
       "265503    tongzhou_aq  2017-11-13 08:00:00    8.0   89.0  500.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality[air_quality['O3']>=460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_quality.iloc[253686,4]=np.nan\n",
    "# air_quality.iloc[86597, 4]=np.nan\n",
    "# air_quality.iloc[15117, 4]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Find missed data for each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 14:00:00\n",
      "2018-04-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "print(air_quality.time.min())\n",
    "print(air_quality.time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from operator import itemgetter\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_missing_data(air_quality, Stations, Pollutants, timeFrom='2017-01-01 14:00:00', timeTo='2018-04-30 23:00:00'):\n",
    "    timeFrom = datetime.datetime.strptime(timeFrom, \"%Y-%m-%d %H:%M:%S\")\n",
    "    timeTo = datetime.datetime.strptime(timeTo, \"%Y-%m-%d %H:%M:%S\")\n",
    "    Hours_Delta = pd.date_range(timeFrom, timeTo, freq='H').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    Times_missed = {}\n",
    "    for station in Stations:\n",
    "        Times_missed[station] = {}\n",
    "        # Find time not in rows.\n",
    "        tmp = air_quality[air_quality['stationId']==station].time.unique()\n",
    "        tmp = list(set(Hours_Delta) - set(tmp))\n",
    "        # In a Station, find time of row with missing pollutant concentation values.\n",
    "        for pollutant in Pollutants:\n",
    "            tmp_nan = air_quality[(air_quality['stationId']==station) & \\\n",
    "                                  (air_quality[pollutant].isnull())].time.unique()     \n",
    "            Times_missed[station][pollutant] = np.concatenate((tmp,tmp_nan))\n",
    "    \n",
    "    # Built a dataframe to record numbers of continuous missing hours for a station. \n",
    "    lost_hour_record = pd.DataFrame(columns=['stationId', 'pollutant', 'start_time', 'counts'])\n",
    "    for station in Stations:\n",
    "        for pollutant in Pollutants:\n",
    "            tmp = [(i, int(datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").timestamp()/3600)) \\\n",
    "                   for i,x in enumerate(sorted(Times_missed[station][pollutant]))]\n",
    "            for key, group in groupby(tmp, lambda x: x[0]-x[1]):\n",
    "                group = list(group)\n",
    "                lost_hours = len(group)\n",
    "                start_hour = datetime.datetime.fromtimestamp(group[0][1]*3600).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                row_num = len(lost_hour_record.index)\n",
    "                lost_hour_record.loc[row_num] = [station, pollutant, start_hour, lost_hours]\n",
    "    return lost_hour_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_hour_record = stat_missing_data(air_quality, Stations, Pollutants)\n",
    "# lost_hour_record.to_csv(data_path+'lost_hour_record.csv',index=None)\n",
    "lost_hour_record = pd.read_csv(data_path+'lost_hour_record.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot missing data distribution.(PM2.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f40aca2a208>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = lost_hour_record[lost_hour_record['pollutant']=='PM2.5'].counts\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, sharex=True)\n",
    "\n",
    "# plot the same data on both axes\n",
    "for i in range(4):\n",
    "    axs[i].hist(tmp, bins=200)\n",
    "    \n",
    "# # zoom-in / limit the view to different portions of the data\n",
    "axs[0].set_ylim(bottom=1000)\n",
    "axs[1].set_ylim(bottom=100, top=1000)  \n",
    "axs[2].set_ylim(bottom=25, top=100)\n",
    "axs[3].set_ylim(bottom=0,top=20)\n",
    "axs[0].spines['bottom'].set_visible(False)\n",
    "axs[3].spines['top'].set_visible(False)\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[1].xaxis.set_visible(False)\n",
    "axs[2].xaxis.set_visible(False)\n",
    "\n",
    "d = .005  # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass to plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=axs[0].transAxes, color='k', clip_on=False)\n",
    "axs[0].plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "axs[0].plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "\n",
    "for i in range(1,3):\n",
    "    axs[i].spines['bottom'].set_visible(False)\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    \n",
    "    kwargs.update(transform=axs[i].transAxes)\n",
    "    axs[i].plot((-d, +d), (-d, +d), **kwargs)\n",
    "    axs[i].plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "    axs[i].plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "    axs[i].plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=axs[3].transAxes)  # switch to the bottom axes\n",
    "axs[3].plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "axs[3].plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(lost_hour_record, pollutant='PM2.5'):\n",
    "    return lost_hour_record[lost_hour_record['pollutant']==pollutant].groupby(['counts']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import Bar\n",
    "bar = Bar(\"Distribution: Counts of continuous missed hours rows\",\n",
    "          'eg:PM2.5 1:6570 指PM2.5连续缺失1小时数据的情况出现6570次'\n",
    "         )\n",
    "for pollutant in Pollutants:\n",
    "    bar.add(pollutant,\n",
    "            func1(lost_hour_record, pollutant).index,\n",
    "            func1(lost_hour_record, pollutant).values, \n",
    "            legend_top='30',\n",
    "            legend_pos='right',\n",
    "            is_stack=True,\n",
    "            # default is X axis，horizontal\n",
    "            is_datazoom_show=True,\n",
    "            datazoom_type=\"slider\",\n",
    "            datazoom_range=[0, 50],\n",
    "            is_toolbox_show=False,\n",
    "            xaxis_name='Counts of continuous missed hours',\n",
    "            yaxis_name='Times',\n",
    "            yaxis_name_gap=60,\n",
    "            legend_selectedmode='single'\n",
    "           )\n",
    "bar.render('./image/lost_record.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Fill missing values(only consider PM2.5, PM10, O3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Add rows with lost hours for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lose time data rows\n",
    "for station in Stations:\n",
    "    tmp = air_quality[air_quality['stationId']==station].time.unique()\n",
    "    tmp = list(set(Hours_Delta) - set(tmp))\n",
    "    tmp_df = pd.DataFrame(tmp, columns=['time'])\n",
    "    tmp_df['stationId'] = station\n",
    "    for pollutant in Pollutants:\n",
    "        tmp_df[pollutant] = np.nan\n",
    "    tmp_df = tmp_df[air_quality.columns]\n",
    "    air_quality = pd.concat([air_quality, tmp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_quality = air_quality.sort_values(by=['stationId','time'])\n",
    "# air_quality = air_quality.reset_index(drop=True)\n",
    "# air_quality.to_csv(data_path+'air_quality.csv',index=None)\n",
    "air_quality = pd.read_csv(data_path+'air_quality.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url: https://stackoverflow.com/questions/24870953/does-iterrows-have-performance-issues  \n",
    "Generally, iterrows should only be used in very very specific cases. This is the general order of precedence for performance of various operations:  \n",
    "1) vectorization  \n",
    "2) using a custom cython routine  \n",
    "3) apply:  a) reductions that can be performed in cython  b) iteration in python space  \n",
    "4) itertuples  \n",
    "5) iterrows  \n",
    "6) updating an empty frame (e.g. using loc one-row-at-a-time)  \n",
    "  \n",
    "Using a custom cython routine is usually too complicated, so let's skip that for now.    \n",
    "1) Vectorization is ALWAYS ALWAYS the first and best choice. However, there are a small set of cases which cannot be vectorized in obvious ways (mostly involving a recurrence). Further, on a smallish frame, it may be faster to do other methods.  \n",
    "3) Apply involves can usually be done by an iterator in Cython space (this is done internally in pandas) (this is a) case.  \n",
    "This is dependent on what is going on inside the apply expression. e.g. df.apply(lambda x: np.sum(x)) will be executed pretty swiftly (of course df.sum(1) is even better). However something like: df.apply(lambda x: x['b'] + 1) will be executed in python space, and consequently is slower.    \n",
    "4) itertuples does not box the data into a Series, just returns it as a tuple  \n",
    "5) iterrows DOES box the data into a Series. Unless you really need this, use another method  \n",
    "6) updating an empty frame a-single-row-at-a-time. I have seen this method used WAY too much. It is by far the slowest. It is probably common place (and reasonably fast for some python structures), but a DataFrame does a fair number of checks on indexing, so this will always be very slow to update a row at a time. Much better to create new structures and concat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. For lost values within continuous hours of three, we fill them with the adjacent values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "5        None\n",
       "6        None\n",
       "8        None\n",
       "9        None\n",
       "11       None\n",
       "12       None\n",
       "14       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "25       None\n",
       "26       None\n",
       "29       None\n",
       "30       None\n",
       "31       None\n",
       "32       None\n",
       "33       None\n",
       "34       None\n",
       "35       None\n",
       "36       None\n",
       "         ... \n",
       "50231    None\n",
       "50232    None\n",
       "50233    None\n",
       "50234    None\n",
       "50235    None\n",
       "50236    None\n",
       "50237    None\n",
       "50238    None\n",
       "50239    None\n",
       "50240    None\n",
       "50241    None\n",
       "50242    None\n",
       "50243    None\n",
       "50245    None\n",
       "50246    None\n",
       "50247    None\n",
       "50248    None\n",
       "50249    None\n",
       "50250    None\n",
       "50251    None\n",
       "50252    None\n",
       "50253    None\n",
       "50254    None\n",
       "50255    None\n",
       "50256    None\n",
       "50257    None\n",
       "50258    None\n",
       "50259    None\n",
       "50260    None\n",
       "50261    None\n",
       "Length: 40631, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame.interpolate(method='linear', axis=0, limit=None, inplace=False,\\\n",
    "#                       limit_direction='forward', limit_area=None, downcast=None, **kwargs)[source]\n",
    "\n",
    "# It took long time...\n",
    "# map pullutants and columns in air quality dataframe.\n",
    "pollutant_map = {'PM2.5': 2, 'PM10': 3, 'O3': 4}\n",
    "threshold=3\n",
    "def fill_nan_data(row):\n",
    "    \n",
    "        station_sindex = air_quality[(air_quality['stationId']==row['stationId']) & \\\n",
    "                                     (air_quality['time']=='2017-01-01 14:00:00')].index[0]\n",
    "        station_eindex = air_quality[(air_quality['stationId']==row['stationId']) & \\\n",
    "                                     (air_quality['time']=='2018-04-30 23:00:00')].index[0]\n",
    "        start_index = air_quality[(air_quality['stationId']==row['stationId']) & \\\n",
    "                                  (air_quality['time']==row['start_time'])].index[0]-1\n",
    "        end_index = start_index + 1 + row['counts']\n",
    "        \n",
    "        if start_index >= station_sindex and end_index <= station_eindex:\n",
    "            p_index = pollutant_map[row['pollutant']]\n",
    "            interval = air_quality.iloc[end_index, p_index] - air_quality.iloc[start_index, p_index]\n",
    "            s_concentration = air_quality.iloc[start_index, p_index]\n",
    "            time_counts = row['counts'] + 1\n",
    "            for i in range(start_index+1, end_index):\n",
    "                if interval == 0:\n",
    "                    air_quality.iloc[i, p_index] = s_concentration\n",
    "                else:\n",
    "                    air_quality.iloc[i, p_index] = s_concentration + interval/time_counts*(i-start_index)\n",
    "\n",
    "lost_hour_record[lost_hour_record.counts<=threshold].apply(lambda row: fill_nan_data(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(data_path+'air_quality_station_info.csv',index_col=0)\n",
    "time_info = pd.read_csv(data_path+'time_info.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_new = air_quality.columns.append(time_info.columns[2:])\n",
    "air_quality = air_quality.merge(time_info,on='time',how='left')[columns_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.For the rest of lossing values, we consider pretrain a model of a pollutant to fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PM2.5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>-0.114345</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>-0.140430</td>\n",
       "      <td>-0.047541</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.019917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PM10</th>\n",
       "      <td>0.742676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014273</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>-0.097578</td>\n",
       "      <td>-0.015307</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.007086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O3</th>\n",
       "      <td>-0.114345</td>\n",
       "      <td>-0.014273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023517</td>\n",
       "      <td>-0.041284</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>-0.014551</td>\n",
       "      <td>-0.250273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>-0.023517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.497294</td>\n",
       "      <td>-0.010794</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>-0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>-0.140430</td>\n",
       "      <td>-0.097578</td>\n",
       "      <td>-0.041284</td>\n",
       "      <td>-0.497294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.018513</td>\n",
       "      <td>-0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.047541</td>\n",
       "      <td>-0.015307</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>-0.010794</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>-0.001458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>-0.014551</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>0.018513</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>-0.250273</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PM2.5      PM10        O3      year     month       day   weekday  \\\n",
       "PM2.5    1.000000  0.742676 -0.114345  0.012630 -0.140430 -0.047541  0.003905   \n",
       "PM10     0.742676  1.000000 -0.014273  0.064326 -0.097578 -0.015307  0.017391   \n",
       "O3      -0.114345 -0.014273  1.000000 -0.023517 -0.041284  0.005326 -0.014551   \n",
       "year     0.012630  0.064326 -0.023517  1.000000 -0.497294 -0.010794 -0.006125   \n",
       "month   -0.140430 -0.097578 -0.041284 -0.497294  1.000000  0.010925  0.018513   \n",
       "day     -0.047541 -0.015307  0.005326 -0.010794  0.010925  1.000000 -0.007794   \n",
       "weekday  0.003905  0.017391 -0.014551 -0.006125  0.018513 -0.007794  1.000000   \n",
       "hour     0.019917  0.007086 -0.250273 -0.000499 -0.001126 -0.001458  0.001304   \n",
       "\n",
       "             hour  \n",
       "PM2.5    0.019917  \n",
       "PM10     0.007086  \n",
       "O3      -0.250273  \n",
       "year    -0.000499  \n",
       "month   -0.001126  \n",
       "day     -0.001458  \n",
       "weekday  0.001304  \n",
       "hour     1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build pretrain model\n",
    "Use last three days(72 hours) datas as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_data(air_quality, length=24*3):\n",
    "    attr = ['PM2.5','PM10','O3','weekday','hour']\n",
    "    train_data = []\n",
    "    for station in Stations:\n",
    "        station_data = air_quality[air_quality.stationId==station].sort_values(by='time')\n",
    "        station_data = station_data[attr].values\n",
    "        for i in range(0, station_data.shape[0]-length):\n",
    "            # Prepare a line of training dataset.\n",
    "            # Features = stationId, stationType, Weekday, Hour\n",
    "            row = [station, stations[stations.stationId==station].station_type.values[0],\\\n",
    "                   station_data[i+length,-2], station_data[i+length,-1]]\n",
    "            history_data = station_data[i:i+length,:3].T.flatten().tolist()\n",
    "            target_data = station_data[i+length,:3].flatten().tolist()\n",
    "            row += history_data + target_data\n",
    "            if pd.isna(row).sum() == 0:\n",
    "                train_data.append(row)\n",
    "    return train_data\n",
    "train_data = build_train_data(air_quality, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131692"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy.save_file met an error. So use another function from package of csv.b\n",
    "import csv\n",
    "\n",
    "with open(data_path+\"air_quality_pretrain_data.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statfeatures(narray, pollutant='PM2.5', d='H'):\n",
    "    '''get_statfeatures(narray, d='H')\n",
    "    Since features of three pollutants are the same, which is not suitable to train three models, \n",
    "    we added another statistical feature for perticular pollutant.\n",
    "    narray: air_quality[:, 4:4+72], namely history data of a perticular pollutant.\n",
    "    '''\n",
    "    if d=='H':\n",
    "        # compute last 72 hours data. (Return 5 features)\n",
    "        max_ = np.max(narray, axis=1)\n",
    "        min_ = np.min(narray, axis=1)\n",
    "        mean_ = np.mean(narray, axis=1)\n",
    "        median_ = np.median(narray, axis=1)\n",
    "        var_ = np.var(narray, axis=1)\n",
    "        return np.hstack((mean_, median_, max_, min_, var_)).reshape(-1,5)\n",
    "    elif d=='D':\n",
    "        # In last 3 day, compute every day's data. (Return 3*5 features)\n",
    "        stat_outcome = np.array([[] for i in range(narray.shape[0])])\n",
    "        for i in range(int(narray.shape[1]/24)):\n",
    "            stat_day = get_statfeatures(narray[:,i*24:(i+1)*24], d='H')\n",
    "            stat_outcome = np.hstack((stat_outcome, stat_day))\n",
    "        return stat_outcome\n",
    "\n",
    "\n",
    "def get_onehot(narray, stationType_map, stationId_map):\n",
    "    '''get_onehot(narray)\n",
    "    Format four features: stationId(35), stationType(4), weekday(7), hour(24) into seventy bool-typed features.\n",
    "    narray: air_quality[:,:4], namely all four features of training data \n",
    "    '''\n",
    "    onehot_data = []\n",
    "    for i in range(narray.shape[0]):\n",
    "        onehot_row = np.zeros(70)\n",
    "        # stationId\n",
    "        onehot_row[stationId_map[narray[i,0]]] = 1\n",
    "        # stationType\n",
    "        onehot_row[35+stationType_map[narray[i,1]]] = 1\n",
    "        # weekday\n",
    "        onehot_row[39+int(narray[i,2])] = 1\n",
    "        # hour\n",
    "        onehot_row[46+int(narray[i,3])] = 1\n",
    "        \n",
    "        onehot_data.append(onehot_row)\n",
    "    return np.array(onehot_data)\n",
    "\n",
    "\n",
    "def build_features(train_data, stations, pollutant='PM2.5', length=24*3):\n",
    "    '''\n",
    "    train_data: source pre-train data.\n",
    "    stations: information of each station, a dataframe.\n",
    "    '''\n",
    "    if pollutant == 'PM2.5':\n",
    "        static_hour = get_statfeatures(train_data[:,4:4+length], d='H')\n",
    "        static_days = get_statfeatures(train_data[:,4:4+length], d='D')\n",
    "    elif pollutant == 'PM10':\n",
    "        static_hour = get_statfeatures(train_data[:, 4+length:4+length*2], d='H')\n",
    "        static_days = get_statfeatures(train_data[:,4+length:4+length*2], d='D')\n",
    "    else:\n",
    "        static_hour = get_statfeatures(train_data[:, 4+length*2:4+length*3], d='H')\n",
    "        static_days = get_statfeatures(train_data[:,4+length*2:4+length*3], d='D')\n",
    "        \n",
    "    stationId_map = {}\n",
    "    for index, station in enumerate(sorted(stations.stationId.unique().tolist())):\n",
    "        stationId_map[station] = index\n",
    "    stationType_map = {}\n",
    "    for index, stationtype in enumerate(stations.station_type.unique().tolist()):\n",
    "        stationType_map[stationtype] = index\n",
    "        \n",
    "    onehot = get_onehot(train_data[:,:4], stationType_map, stationId_map)\n",
    "    \n",
    "    return np.hstack((onehot, train_data[:,4:-3], static_hour, static_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(train_data, stations, pollutant='PM2.5', length=24*3):\n",
    "    if pollutant == 'PM2.5':\n",
    "        dataset_Y = train_data[:,-3]\n",
    "    elif pollutant == 'PM10':\n",
    "        dataset_Y = train_data[:,-2]\n",
    "    else:\n",
    "        dataset_Y = train_data[:,-1]   \n",
    "    dataset_X = build_features(train_data, stations, pollutant, length)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(dataset_X, dataset_Y, test_size=0.2, random_state=10)\n",
    "    \n",
    "    # load regression model\n",
    "    reg = xgb.XGBRegressor()\n",
    "    reg.fit(train_X, train_Y)\n",
    "    \n",
    "    # validation\n",
    "    pred_Y = reg.predict(test_X)\n",
    "    validation_error = np.mean(np.abs(pred_Y - test_Y) / (pred_Y + test_Y) * 2)\n",
    "    print('Validation error of {0} is {1}'.format(pollutant, str(validation_error)))\n",
    "    \n",
    "    model_file = model_path + pollutant + '_fillmissingdata.model'\n",
    "    joblib.dump(reg, model_file)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell on Colab.\n",
    "\n",
    "reg_PM25 = built_model(train_data, stations, 'PM2.5')\n",
    "# Validation error of PM2.5 is 0.21988583652019708\n",
    "\n",
    "reg_PM10 = built_model(train_data, stations, 'PM10')\n",
    "# Validation error of PM10 is 0.19306589695892443\n",
    "\n",
    "reg_O3 = built_model(train_data, stations, 'O3')\n",
    "# Validation error of O3 is 0.2787606643604839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have to use past three days air quality concentraction to predict current AQI, we have to make sure that the first three days' data are not nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values of PM2.5 in first 3.0 days:\t 15\n",
      "Number of missing values of PM10 in first 3.0 days:\t 1124\n",
      "Number of missing values of O3 in first 3.0 days:\t 12\n"
     ]
    }
   ],
   "source": [
    "def firstdays_miss(air_quality, pollutant='PM2.5', threshold=3*24):\n",
    "    start_time = datetime.datetime.strptime('2017-01-01 00:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = start_time + datetime.timedelta(hours=threshold)\n",
    "    end_time = datetime.datetime.strftime(end_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    counts = air_quality[(air_quality['time']<end_time)& \\\n",
    "                         (air_quality[pollutant].isna())].shape[0]\n",
    "    print('Number of missing values of {0} in first {1} days:\\t {2}'.format(pollutant, str(threshold/24), counts))\n",
    "firstdays_miss(air_quality, 'PM2.5')\n",
    "firstdays_miss(air_quality, 'PM10')\n",
    "firstdays_miss(air_quality, 'O3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>start_time</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-03 09:00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stationId pollutant           start_time  counts\n",
       "14000  guanyuan_aq     PM2.5  2017-01-03 09:00:00      22"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost_hour_record[(lost_hour_record['pollutant']=='PM2.5') & \\\n",
    "                 (lost_hour_record['counts']>3) & \\\n",
    "                 (lost_hour_record['start_time']<='2017-01-04 14:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using average pollutant concentration of same hour in same weekday in recent two months to fill missing data in first three days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "def fill_firstdays(air_quality, pollutant, threshold=24*3, accordingto=2):\n",
    "    start_time = datetime.datetime.strptime('2017-01-01 14:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = start_time + datetime.timedelta(hours=threshold)\n",
    "    end_time = datetime.datetime.strftime(end_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    # Find missing pollutant air quality's index in first 3 days.\n",
    "    missing_index = air_quality[(air_quality['time']<end_time)&\\\n",
    "                                (air_quality[pollutant].isna())].index\n",
    "    pollutant_map = {'PM2.5':2, 'PM10':3, 'O3':4}\n",
    "    for index in missing_index:\n",
    "        cur_station = air_quality.loc[index,'stationId']\n",
    "        cur_time = air_quality.loc[index,'time']\n",
    "        cur_weekday = air_quality.loc[index,'weekday']\n",
    "        cur_hour = air_quality.loc[index,'hour']\n",
    "        # find reference data\n",
    "        refer_period = accordingto\n",
    "        while True:\n",
    "            time_period = datetime.datetime.strptime(cur_time, \"%Y-%m-%d %H:%M:%S\") + relativedelta(months=refer_period)\n",
    "            time_period = datetime.datetime.strftime(time_period, \"%Y-%m-%d %H:%M:%S\")              \n",
    "            reference_data = air_quality[(air_quality['stationId']==cur_station)&\\\n",
    "                                         (air_quality['time'] > cur_time)&\\\n",
    "                                         (air_quality['time'] <= time_period)&\\\n",
    "                                         (air_quality['weekday'] == cur_weekday)&\\\n",
    "                                         (air_quality['hour'] == cur_hour)][pollutant].values\n",
    "            reference_data = [x for x in reference_data if str(x) != 'nan']\n",
    "            if len(reference_data) == 0:\n",
    "                # if in the next two months, reference data is all nan, add one months data to reference \n",
    "                refer_period += 1\n",
    "                continue\n",
    "            air_quality.iloc[index, pollutant_map[pollutant]] = np.mean(reference_data)\n",
    "            # print(reference_data)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_firstdays(air_quality, 'PM2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-01-04 14:00:00'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.strptime('2017-01-01 14:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "end_time = start_time + datetime.timedelta(hours=72)\n",
    "datetime.datetime.strftime(end_time, \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>start_time</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>aotizhongxin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 19:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>aotizhongxin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 07:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>aotizhongxin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 03:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>aotizhongxin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 08:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>beibuxinqu_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 16:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>beibuxinqu_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 14:00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 20:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 02:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>daxing_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 13:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 15:00:00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 11:00:00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 09:00:00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>dingling_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 10:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>donggaocun_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8872</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 19:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 09:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 23:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10412</th>\n",
       "      <td>dongsihuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 20:00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>dongsihuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 20:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10414</th>\n",
       "      <td>dongsihuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 08:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10417</th>\n",
       "      <td>dongsihuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 05:00:00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11647</th>\n",
       "      <td>fangshan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 21:00:00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11650</th>\n",
       "      <td>fangshan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 20:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11655</th>\n",
       "      <td>fangshan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 04:00:00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13029</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 20:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 02:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13031</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 19:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13036</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 05:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13038</th>\n",
       "      <td>fengtaihuayuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14258</th>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 18:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36247</th>\n",
       "      <td>wanliu_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 02:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37697</th>\n",
       "      <td>wanshouxigong_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 20:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37698</th>\n",
       "      <td>wanshouxigong_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 03:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37700</th>\n",
       "      <td>wanshouxigong_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39291</th>\n",
       "      <td>xizhimenbei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39292</th>\n",
       "      <td>xizhimenbei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 17:00:00</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40860</th>\n",
       "      <td>yanqin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 18:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40861</th>\n",
       "      <td>yanqin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 16:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40865</th>\n",
       "      <td>yanqin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 19:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40868</th>\n",
       "      <td>yanqin_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 14:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43468</th>\n",
       "      <td>yongdingmennei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43469</th>\n",
       "      <td>yongdingmennei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 02:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43470</th>\n",
       "      <td>yongdingmennei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 20:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43471</th>\n",
       "      <td>yongdingmennei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 03:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43472</th>\n",
       "      <td>yongdingmennei_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 09:00:00</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45254</th>\n",
       "      <td>yongledian_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 14:00:00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45255</th>\n",
       "      <td>yongledian_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 09:00:00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46663</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 20:00:00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46664</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 15:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46667</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 16:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46668</th>\n",
       "      <td>yufa_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 05:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48131</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 19:00:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48132</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 14:00:00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48134</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 21:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48135</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 02:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48136</th>\n",
       "      <td>yungang_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 12:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49396</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-01 17:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49397</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-02 12:00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49400</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-03 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49401</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2017-01-04 03:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               stationId pollutant           start_time  counts\n",
       "253      aotizhongxin_aq      PM10  2017-01-01 19:00:00       9\n",
       "255      aotizhongxin_aq      PM10  2017-01-02 07:00:00      25\n",
       "260      aotizhongxin_aq      PM10  2017-01-04 03:00:00       4\n",
       "261      aotizhongxin_aq      PM10  2017-01-04 08:00:00      13\n",
       "3064       beibuxinqu_aq      PM10  2017-01-01 16:00:00      38\n",
       "3067       beibuxinqu_aq      PM10  2017-01-03 14:00:00      19\n",
       "4561           daxing_aq      PM10  2017-01-01 20:00:00       4\n",
       "4562           daxing_aq      PM10  2017-01-02 02:00:00       8\n",
       "4569           daxing_aq      PM10  2017-01-04 13:00:00      10\n",
       "5788         dingling_aq      PM10  2017-01-01 15:00:00      15\n",
       "5789         dingling_aq      PM10  2017-01-02 11:00:00      16\n",
       "5791         dingling_aq      PM10  2017-01-03 09:00:00      15\n",
       "5794         dingling_aq      PM10  2017-01-04 10:00:00       6\n",
       "7200       donggaocun_aq      PM10  2017-01-01 14:00:00      90\n",
       "8872           dongsi_aq      PM10  2017-01-01 19:00:00       9\n",
       "8874           dongsi_aq      PM10  2017-01-02 09:00:00       4\n",
       "8878           dongsi_aq      PM10  2017-01-03 23:00:00       5\n",
       "10412      dongsihuan_aq      PM10  2017-01-01 20:00:00      22\n",
       "10413      dongsihuan_aq      PM10  2017-01-02 20:00:00      11\n",
       "10414      dongsihuan_aq      PM10  2017-01-03 08:00:00       5\n",
       "10417      dongsihuan_aq      PM10  2017-01-04 05:00:00      17\n",
       "11647        fangshan_aq      PM10  2017-01-01 21:00:00      15\n",
       "11650        fangshan_aq      PM10  2017-01-02 20:00:00       5\n",
       "11655        fangshan_aq      PM10  2017-01-04 04:00:00      16\n",
       "13029  fengtaihuayuan_aq      PM10  2017-01-01 20:00:00       4\n",
       "13030  fengtaihuayuan_aq      PM10  2017-01-02 02:00:00      12\n",
       "13031  fengtaihuayuan_aq      PM10  2017-01-02 19:00:00       4\n",
       "13036  fengtaihuayuan_aq      PM10  2017-01-04 05:00:00       4\n",
       "13038  fengtaihuayuan_aq      PM10  2017-01-04 12:00:00      10\n",
       "14258        guanyuan_aq      PM10  2017-01-01 18:00:00       9\n",
       "...                  ...       ...                  ...     ...\n",
       "36247          wanliu_aq      PM10  2017-01-03 02:00:00       4\n",
       "37697   wanshouxigong_aq      PM10  2017-01-01 20:00:00       5\n",
       "37698   wanshouxigong_aq      PM10  2017-01-02 03:00:00      10\n",
       "37700   wanshouxigong_aq      PM10  2017-01-02 19:00:00       6\n",
       "39291     xizhimenbei_aq      PM10  2017-01-01 14:00:00      49\n",
       "39292     xizhimenbei_aq      PM10  2017-01-03 17:00:00      29\n",
       "40860          yanqin_aq      PM10  2017-01-01 18:00:00       7\n",
       "40861          yanqin_aq      PM10  2017-01-02 16:00:00       8\n",
       "40865          yanqin_aq      PM10  2017-01-03 19:00:00       4\n",
       "40868          yanqin_aq      PM10  2017-01-04 14:00:00       8\n",
       "43468  yongdingmennei_aq      PM10  2017-01-01 14:00:00      11\n",
       "43469  yongdingmennei_aq      PM10  2017-01-02 02:00:00      41\n",
       "43470  yongdingmennei_aq      PM10  2017-01-03 20:00:00       6\n",
       "43471  yongdingmennei_aq      PM10  2017-01-04 03:00:00       4\n",
       "43472  yongdingmennei_aq      PM10  2017-01-04 09:00:00     123\n",
       "45254      yongledian_aq      PM10  2017-01-01 14:00:00      17\n",
       "45255      yongledian_aq      PM10  2017-01-02 09:00:00      55\n",
       "46663            yufa_aq      PM10  2017-01-01 20:00:00      15\n",
       "46664            yufa_aq      PM10  2017-01-02 15:00:00       8\n",
       "46667            yufa_aq      PM10  2017-01-03 16:00:00      12\n",
       "46668            yufa_aq      PM10  2017-01-04 05:00:00       6\n",
       "48131         yungang_aq      PM10  2017-01-01 19:00:00      18\n",
       "48132         yungang_aq      PM10  2017-01-02 14:00:00      17\n",
       "48134         yungang_aq      PM10  2017-01-03 21:00:00       4\n",
       "48135         yungang_aq      PM10  2017-01-04 02:00:00       9\n",
       "48136         yungang_aq      PM10  2017-01-04 12:00:00       5\n",
       "49396       zhiwuyuan_aq      PM10  2017-01-01 17:00:00      13\n",
       "49397       zhiwuyuan_aq      PM10  2017-01-02 12:00:00      19\n",
       "49400       zhiwuyuan_aq      PM10  2017-01-03 19:00:00       6\n",
       "49401       zhiwuyuan_aq      PM10  2017-01-04 03:00:00      13\n",
       "\n",
       "[118 rows x 4 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost_hour_record[(lost_hour_record['pollutant']=='PM10') & \\\n",
    "                 (lost_hour_record['counts']>3) & \\\n",
    "                 (lost_hour_record['start_time']<='2017-01-04 14:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using average pollutant concentration of same hour in same weekday in recent two months to fill missing data in first three days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_firstdays(air_quality, 'PM10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>start_time</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>O3</td>\n",
       "      <td>2017-01-04 06:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>O3</td>\n",
       "      <td>2017-01-03 08:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>O3</td>\n",
       "      <td>2017-01-04 03:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38502</th>\n",
       "      <td>wanshouxigong_aq</td>\n",
       "      <td>O3</td>\n",
       "      <td>2017-01-04 06:00:00</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42791</th>\n",
       "      <td>yizhuang_aq</td>\n",
       "      <td>O3</td>\n",
       "      <td>2017-01-03 05:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stationId pollutant           start_time  counts\n",
       "9599          dongsi_aq        O3  2017-01-04 06:00:00       4\n",
       "14976       guanyuan_aq        O3  2017-01-03 08:00:00       6\n",
       "14977       guanyuan_aq        O3  2017-01-04 03:00:00       4\n",
       "38502  wanshouxigong_aq        O3  2017-01-04 06:00:00      23\n",
       "42791       yizhuang_aq        O3  2017-01-03 05:00:00       6"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost_hour_record[(lost_hour_record['pollutant']=='O3') & \\\n",
    "                 (lost_hour_record['counts']>3) & \\\n",
    "                 (lost_hour_record['start_time']<='2017-01-04 14:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing values of O3 in first three days is not so intensive, we directly fill them with adjacent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = air_quality[(air_quality['stationId']=='yizhuang_aq') &\\\n",
    "                (air_quality['time']>='2017-01-03 04:00:00') &\\\n",
    "                (air_quality['time']<='2017-01-03 11:00:00')]['O3']\n",
    "air_quality.iloc[a.index,4] = a.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = air_quality[(air_quality['stationId']=='guanyuan_aq') &\\\n",
    "                (air_quality['time']>='2017-01-03 07:00:00') &\\\n",
    "                (air_quality['time']<='2017-01-03 14:00:00')]['O3']\n",
    "air_quality.iloc[b.index,4] = b.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = air_quality[(air_quality['stationId']=='guanyuan_aq') &\\\n",
    "                (air_quality['time']>='2017-01-04 02:00:00') &\\\n",
    "                (air_quality['time']<='2017-01-04 07:00:00')]['O3']\n",
    "air_quality.iloc[c.index,4] = c.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = air_quality[(air_quality['stationId']=='dongsi_aq') &\\\n",
    "                (air_quality['time']>='2017-01-04 05:00:00') &\\\n",
    "                (air_quality['time']<='2017-01-04 10:00:00')]['O3']\n",
    "air_quality.iloc[d.index,4] = d.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_firstdays(air_quality, 'O3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, the first three days data is all filled!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>time</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>O3</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [stationId, time, PM2.5, PM10, O3, year, month, day, weekday, hour]\n",
       "Index: []"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality[(air_quality['time']<'2017-01-04 14:00:00') &\\\n",
    "            ((air_quality['PM2.5'].isna()) |\\\n",
    "             (air_quality['PM10'].isna()) |\\\n",
    "             (air_quality['O3'].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.to_csv(data_path+'air_quality_fillthree.csv')\n",
    "# air_quality = pd.read_csv(data_path+'air_quality_fillthree.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use trained model to fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute lost_hour_record again.\n",
    "new_lost_hour_record = stat_missing_data(air_quality, Stations, Pollutants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>start_time</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-06 13:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-06 22:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-08 15:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9275</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-09 14:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-10 16:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-11 13:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9278</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-17 08:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-18 08:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-24 08:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-25 13:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9282</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-26 08:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9283</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-27 09:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-01-29 11:00:00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-05 03:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-06 02:00:00</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-08 15:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-15 16:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-16 03:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-18 00:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-02-18 08:00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-10 19:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-11 01:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-11 06:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9295</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-11 15:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-12 08:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-12 14:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9298</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-13 08:00:00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9299</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-14 03:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9300</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-15 21:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9301</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-03-16 04:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-04-20 19:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-04-23 07:00:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-05-05 18:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-05-18 09:00:00</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-05-29 16:00:00</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-05-31 16:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-01 16:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-02 16:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-04 16:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-05 10:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-09 03:00:00</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-13 09:00:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9314</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-14 08:00:00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-06-16 01:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-07-01 16:00:00</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-07-09 01:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-07-22 18:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-07-24 00:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-08-09 20:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-08-18 07:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-08-25 17:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-09-25 09:00:00</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-10-12 07:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-11-07 09:00:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>zhiwuyuan_aq</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2017-11-24 03:00:00</td>\n",
       "      <td>3789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stationId pollutant           start_time counts\n",
       "9272  zhiwuyuan_aq     PM2.5  2017-01-06 13:00:00      7\n",
       "9273  zhiwuyuan_aq     PM2.5  2017-01-06 22:00:00      8\n",
       "9274  zhiwuyuan_aq     PM2.5  2017-01-08 15:00:00      6\n",
       "9275  zhiwuyuan_aq     PM2.5  2017-01-09 14:00:00     20\n",
       "9276  zhiwuyuan_aq     PM2.5  2017-01-10 16:00:00     10\n",
       "9277  zhiwuyuan_aq     PM2.5  2017-01-11 13:00:00     21\n",
       "9278  zhiwuyuan_aq     PM2.5  2017-01-17 08:00:00      4\n",
       "9279  zhiwuyuan_aq     PM2.5  2017-01-18 08:00:00      7\n",
       "9280  zhiwuyuan_aq     PM2.5  2017-01-24 08:00:00     12\n",
       "9281  zhiwuyuan_aq     PM2.5  2017-01-25 13:00:00      7\n",
       "9282  zhiwuyuan_aq     PM2.5  2017-01-26 08:00:00     12\n",
       "9283  zhiwuyuan_aq     PM2.5  2017-01-27 09:00:00      6\n",
       "9284  zhiwuyuan_aq     PM2.5  2017-01-29 11:00:00     42\n",
       "9285  zhiwuyuan_aq     PM2.5  2017-02-05 03:00:00     11\n",
       "9286  zhiwuyuan_aq     PM2.5  2017-02-06 02:00:00     26\n",
       "9287  zhiwuyuan_aq     PM2.5  2017-02-08 15:00:00     10\n",
       "9288  zhiwuyuan_aq     PM2.5  2017-02-15 16:00:00      7\n",
       "9289  zhiwuyuan_aq     PM2.5  2017-02-16 03:00:00      6\n",
       "9290  zhiwuyuan_aq     PM2.5  2017-02-18 00:00:00      7\n",
       "9291  zhiwuyuan_aq     PM2.5  2017-02-18 08:00:00     22\n",
       "9292  zhiwuyuan_aq     PM2.5  2017-03-10 19:00:00      5\n",
       "9293  zhiwuyuan_aq     PM2.5  2017-03-11 01:00:00      4\n",
       "9294  zhiwuyuan_aq     PM2.5  2017-03-11 06:00:00      6\n",
       "9295  zhiwuyuan_aq     PM2.5  2017-03-11 15:00:00      5\n",
       "9296  zhiwuyuan_aq     PM2.5  2017-03-12 08:00:00      5\n",
       "9297  zhiwuyuan_aq     PM2.5  2017-03-12 14:00:00      6\n",
       "9298  zhiwuyuan_aq     PM2.5  2017-03-13 08:00:00     16\n",
       "9299  zhiwuyuan_aq     PM2.5  2017-03-14 03:00:00      9\n",
       "9300  zhiwuyuan_aq     PM2.5  2017-03-15 21:00:00      4\n",
       "9301  zhiwuyuan_aq     PM2.5  2017-03-16 04:00:00      4\n",
       "9302  zhiwuyuan_aq     PM2.5  2017-04-20 19:00:00      4\n",
       "9303  zhiwuyuan_aq     PM2.5  2017-04-23 07:00:00     18\n",
       "9304  zhiwuyuan_aq     PM2.5  2017-05-05 18:00:00      4\n",
       "9305  zhiwuyuan_aq     PM2.5  2017-05-18 09:00:00    246\n",
       "9306  zhiwuyuan_aq     PM2.5  2017-05-29 16:00:00     37\n",
       "9307  zhiwuyuan_aq     PM2.5  2017-05-31 16:00:00      8\n",
       "9308  zhiwuyuan_aq     PM2.5  2017-06-01 16:00:00      7\n",
       "9309  zhiwuyuan_aq     PM2.5  2017-06-02 16:00:00      9\n",
       "9310  zhiwuyuan_aq     PM2.5  2017-06-04 16:00:00      7\n",
       "9311  zhiwuyuan_aq     PM2.5  2017-06-05 10:00:00      4\n",
       "9312  zhiwuyuan_aq     PM2.5  2017-06-09 03:00:00     99\n",
       "9313  zhiwuyuan_aq     PM2.5  2017-06-13 09:00:00     18\n",
       "9314  zhiwuyuan_aq     PM2.5  2017-06-14 08:00:00     36\n",
       "9315  zhiwuyuan_aq     PM2.5  2017-06-16 01:00:00     10\n",
       "9316  zhiwuyuan_aq     PM2.5  2017-07-01 16:00:00    168\n",
       "9317  zhiwuyuan_aq     PM2.5  2017-07-09 01:00:00     12\n",
       "9318  zhiwuyuan_aq     PM2.5  2017-07-22 18:00:00      7\n",
       "9319  zhiwuyuan_aq     PM2.5  2017-07-24 00:00:00      5\n",
       "9320  zhiwuyuan_aq     PM2.5  2017-08-09 20:00:00      7\n",
       "9321  zhiwuyuan_aq     PM2.5  2017-08-18 07:00:00      6\n",
       "9322  zhiwuyuan_aq     PM2.5  2017-08-25 17:00:00      5\n",
       "9323  zhiwuyuan_aq     PM2.5  2017-09-25 09:00:00     47\n",
       "9324  zhiwuyuan_aq     PM2.5  2017-10-12 07:00:00     25\n",
       "9325  zhiwuyuan_aq     PM2.5  2017-11-07 09:00:00     20\n",
       "9326  zhiwuyuan_aq     PM2.5  2017-11-24 03:00:00   3789"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zhiwuyuan_aq 2017-11-24 03:00:00 all three pollutants missed 3789 records.\n",
    "new_lost_hour_record[(new_lost_hour_record['stationId']=='zhiwuyuan_aq') &\\\n",
    "                     (new_lost_hour_record['pollutant']=='PM2.5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_row(narray, stationType_map, stationId_map):\n",
    "    onehot_row = np.zeros(70)\n",
    "    # stationId\n",
    "    onehot_row[stationId_map[narray[0]]] = 1\n",
    "    # stationType\n",
    "    onehot_row[35+stationType_map[narray[1]]] = 1\n",
    "    # weekday\n",
    "    onehot_row[39+int(narray[2])] = 1\n",
    "    # hour\n",
    "    onehot_row[46+int(narray[3])] = 1\n",
    "        \n",
    "    return onehot_row\n",
    "\n",
    "def get_statfeatures_row(narray, pollutant='PM2.5', d='H'):\n",
    "    if d=='H':\n",
    "        # compute last 72 hours data. (Return 5 features)\n",
    "        max_ = np.max(narray)\n",
    "        min_ = np.min(narray)\n",
    "        mean_ = np.mean(narray)\n",
    "        median_ = np.median(narray)\n",
    "        var_ = np.var(narray)\n",
    "        return np.hstack((mean_, median_, max_, min_, var_))\n",
    "    elif d=='D':\n",
    "        # In last 3 day, compute every day's data. (Return 3*5 features)\n",
    "        stat_outcome = np.array([])\n",
    "        for i in range(int(len(narray)/24)):\n",
    "            stat_day = get_statfeatures_row(narray[i*24:(i+1)*24], d='H')\n",
    "            stat_outcome = np.hstack((stat_outcome, stat_day))\n",
    "        return stat_outcome\n",
    "    \n",
    "def build_features_row(train_data, stations, pollutant='PM2.5', length=24*3):\n",
    "    if pollutant == 'PM2.5':\n",
    "        static_hour = get_statfeatures_row(train_data[4:4+length], d='H')\n",
    "        static_days = get_statfeatures_row(train_data[4:4+length], d='D')\n",
    "    elif pollutant == 'PM10':\n",
    "        static_hour = get_statfeatures_row(train_data[4+length:4+length*2], d='H')\n",
    "        static_days = get_statfeatures_row(train_data[4+length:4+length*2], d='D')\n",
    "    else:\n",
    "        static_hour = get_statfeatures_row(train_data[4+length*2:4+length*3], d='H')\n",
    "        static_days = get_statfeatures_row(train_data[4+length*2:4+length*3], d='D')  \n",
    "        \n",
    "    onehot = get_onehot_row(train_data[:4], stationType_map, stationId_map)\n",
    "    \n",
    "    return np.hstack((onehot, train_data[4:], static_hour, static_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_filldata(air_quality, stations, length=24*3):\n",
    "    attr = ['PM2.5','PM10','O3','weekday','hour']\n",
    "    \n",
    "    smape_PM25_sum = 0\n",
    "    count_PM25 = 0\n",
    "    smape_PM10_sum = 0\n",
    "    count_PM10 = 0\n",
    "    smape_O3_sum = 0\n",
    "    count_O3 = 0\n",
    "    \n",
    "    for station in stations.stationId.unique().tolist():\n",
    "        station_index = air_quality[air_quality.stationId==station].index\n",
    "        station_data = air_quality[air_quality.stationId==station]\n",
    "        station_data = station_data[attr].values\n",
    "        for i in range(0, station_data.shape[0]-length):\n",
    "            # Prepare a line of testing dataset.\n",
    "            # Features = stationId, stationType, Weekday, Hour\n",
    "            station_data = air_quality[air_quality.stationId==station][attr].values\n",
    "            row = [station, stations[stations.stationId==station].station_type.values[0],\\\n",
    "                   station_data[i+length,-2], station_data[i+length,-1]]\n",
    "            history_data = station_data[i:i+length,:3].T.flatten().tolist()\n",
    "            row += history_data \n",
    "            if pd.isna(history_data).sum() > 0:\n",
    "                continue\n",
    "                \n",
    "            # PM2.5\n",
    "            test_Y = station_data[i+length,0]\n",
    "            test_X = build_features_row(row, stations, 'PM2.5', length)\n",
    "            pred_Y = reg_PM25.predict([test_X])[0]\n",
    "            if np.isnan(test_Y):\n",
    "                air_quality.iloc[station_index[i+length],2] = pred_Y\n",
    "            else:\n",
    "                count_PM25 += 1\n",
    "                smape_PM25_sum += np.abs(pred_Y - test_Y) / (pred_Y + test_Y) * 2\n",
    "                \n",
    "            # PM10\n",
    "            test_Y = station_data[i+length,1]\n",
    "            test_X = build_features_row(row, stations, 'PM10', length)\n",
    "            pred_Y = reg_PM10.predict([test_X])[0]\n",
    "            if np.isnan(test_Y):\n",
    "                air_quality.iloc[station_index[i+length],3] = pred_Y\n",
    "            else:\n",
    "                count_PM10 += 1\n",
    "                smape_PM10_sum += np.abs(pred_Y - test_Y) / (pred_Y + test_Y) * 2\n",
    "                \n",
    "            # O3\n",
    "            test_Y = station_data[i+length,2]\n",
    "            test_X = build_features_row(row, stations, 'O3', length)\n",
    "            pred_Y = reg_O3.predict([test_X])[0]\n",
    "            if np.isnan(test_Y):\n",
    "                air_quality.iloc[station_index[i+length],4] = pred_Y\n",
    "            else:\n",
    "                count_O3 += 1\n",
    "                smape_O3_sum += np.abs(pred_Y - test_Y) / (pred_Y + test_Y) * 2\n",
    "    print('PM2.5: Test on {0} records, SMAPE is {1}'.format(str(count_PM25), str(smape_PM25_sum/count_PM25)))\n",
    "    print('PM10: Test on {0} records, SMAPE is {1}'.format(str(count_PM10), str(smape_PM10_sum/count_PM10)))\n",
    "    print('O3: Test on {0} records, SMAPE is {1}'.format(str(count_O3), str(smape_O3_sum/count_O3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code on colab\n",
    "predict_filldata(air_quality, stations, length=24*3)\n",
    "# PM2.5: Test on 363897 records, SMAPE is 0.217603987484511\n",
    "# PM10: Test on 306011 records, SMAPE is 0.2186182912651704\n",
    "# O3: Test on 365225 records, SMAPE is 0.27200874748285714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.to_csv(data_path+'air_quality_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
